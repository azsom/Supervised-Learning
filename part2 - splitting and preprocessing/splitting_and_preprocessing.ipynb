{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Welcome to Supervised Learning</center>\n",
    "## <center>Part 2: How to prepare your data for supervised machine learning</center>\n",
    "## <center>Instructor: Andras Zsom</center>\n",
    "### <center>https://github.com/azsom/Supervised-Learning<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The topic of the course series: supervised Machine Learning (ML)\n",
    "- how to build an ML pipeline from beginning to deployment\n",
    "- we assume you already performed data cleaning\n",
    "- this is the first course out of 6 courses\n",
    "    - Part 1: Introduction to machine learning and the bias-variance tradeoff\n",
    "    - **Part 2: How to prepare your data for supervised machine learning**\n",
    "    - Part 3: Evaluation metrics in supervised machine learning\n",
    "    - Part 4: SVMs, Random Forests, XGBoost\n",
    "    - Part 5: Missing data in supervised ML\n",
    "    - Part 6: Interpretability\n",
    "- you can complete the courses in sequence or complete individual courses based on your interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured data\n",
    "| X|feature_1|feature_2|...|feature_j|...|feature_m|<font color='red'>Y</font>|\n",
    "|-|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|__data_point_1__|x_11|x_12|...|x_1j|...|x_1m|__<font color='red'>y_1</font>__|\n",
    "|__data_point_2__|x_21|x_22|...|x_2j|...|x_2m|__<font color='red'>y_2</font>__|\n",
    "|__...__|...|...|...|...|...|...|__<font color='red'>...</font>__|\n",
    "|__data_point_i__|x_i1|x_i2|...|x_ij|...|x_im|__<font color='red'>y_i</font>__|\n",
    "|__...__|...|...|...|...|...|...|__<font color='red'>...</font>__|\n",
    "|__data_point_n__|x_n1|x_n2|...|x_nj|...|x_nm|__<font color='red'>y_n</font>__|\n",
    "\n",
    "We focus on the feature matrix (X) in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives of this course\n",
    "\n",
    "By the end of the course, you will be able to\n",
    "- describe why data splitting is necessary in machine learning\n",
    "- summarize the properties of IID data\n",
    "- list examples of non-IID datasets\n",
    "- apply IID splitting techniques\n",
    "- apply non-IID splitting techniques\n",
    "- identify when a custom splitting strategy is necessary\n",
    "- describe the two motivating concepts behind preprocessing\n",
    "- apply various preprocessors to categorical and continuous features\n",
    "- perform preprocessing with a sklearn pipeline and ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Split IID data\n",
    "### Learning objectives of this module:\n",
    "- describe why data splitting is necessary in machine learning\n",
    "- summarize the properties of IID data\n",
    "- apply IID splitting techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we split the data?\n",
    "- we want to find the best hyper-parameters of our ML algorithms\n",
    "   - fit models to training data\n",
    "   - evaluate each model on validation set\n",
    "   - we find hyper-parameter values that optimize the validation score\n",
    "- we want to know how the model will perform on previously unseen data - the generalization error\n",
    "   - apply our final model on the test set\n",
    "   \n",
    "### We need to split the data into three parts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask yourself these questions!\n",
    "- What is the intended use of the model? What is it supposed to do/predict?\n",
    "- What data/info do you have available at the time of prediction?\n",
    "- Your split must mimic the intended use of the model only then will you accurately estimate how well the model will perform on previously unseen points (generalization error).\n",
    "- two examples:\n",
    "    - if you want to predict the outcome of a new patient's visit to the ER:\n",
    "        - your test score must be based on patients not included in training and validation\n",
    "        - your validation score must be based on patients not included in training\n",
    "        - points of one patient should not be distributed over multiple sets because your generalization error will be off\n",
    "    - predict stocks price\n",
    "        - it is a time series data\n",
    "        - if you predict the stocks price at a certain time in development, make sure that you only use information predating that time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How should we split the data into train/validation/test?\n",
    "\n",
    "- data is **Independent and Identically Distributed** (iid)\n",
    "   - all samples stem from the same generative process and the generative process is assumed to have no memory of past generated samples\n",
    "   - identify cats and dogs on images\n",
    "   - predict the house price\n",
    "   - predict if someone's salary is above or below 50k\n",
    "- examples of not iid data:\n",
    "   - data generated by time-dependent processes\n",
    "   - data has group structure (samples collected from e.g., different subjects, experiments, measurement devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Splitting strategies for iid data: basic approach\n",
    "- 60% train, 20% validation, 20% test for small datasets\n",
    "- 98% train, 1% validation, 1% test for large datasets\n",
    "    - if you have 1 million points, you still have 10000 points in validation and test which is plenty to assess model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's work with the adult data!\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         <=50K\n",
      "1         <=50K\n",
      "2         <=50K\n",
      "3         <=50K\n",
      "4         <=50K\n",
      "          ...  \n",
      "32556     <=50K\n",
      "32557      >50K\n",
      "32558     <=50K\n",
      "32559     <=50K\n",
      "32560      >50K\n",
      "Name: gross-income, Length: 32561, dtype: object\n",
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  \n",
      "0          2174             0              40   United-States  \n",
      "1             0             0              13   United-States  \n",
      "2             0             0              40   United-States  \n",
      "3             0             0              40   United-States  \n",
      "4             0             0              40            Cuba  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('data/adult_data.csv')\n",
    "\n",
    "# let's separate the feature matrix X, and target variable y\n",
    "y = df['gross-income'] # remember, we want to predict who earns more than 50k or less than 50k\n",
    "X = df.loc[:, df.columns != 'gross-income'] # all other columns are features\n",
    "print(y)\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int or RandomState instance, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: (19536, 14) (19536,)\n",
      "(13025, 14) (13025,)\n",
      "       age   workclass  fnlwgt      education  education-num  \\\n",
      "25823   31     Private   87418      Assoc-voc             11   \n",
      "10274   41     Private  121718   Some-college             10   \n",
      "27652   61     Private   79827        HS-grad              9   \n",
      "13941   33   State-gov  156015      Bachelors             13   \n",
      "31384   38     Private  167882   Some-college             10   \n",
      "\n",
      "            marital-status        occupation     relationship    race  \\\n",
      "25823   Married-civ-spouse   Exec-managerial          Husband   White   \n",
      "10274   Married-civ-spouse      Craft-repair          Husband   White   \n",
      "27652   Married-civ-spouse   Exec-managerial          Husband   White   \n",
      "13941   Married-civ-spouse   Exec-managerial          Husband   White   \n",
      "31384              Widowed     Other-service   Other-relative   Black   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
      "25823     Male             0             0              40   United-States  \n",
      "10274     Male             0             0              40           Italy  \n",
      "27652     Male             0             0              50   United-States  \n",
      "13941     Male             0             0              40   United-States  \n",
      "31384   Female             0             0              45           Haiti  \n",
      "validation set: (6512, 14) (6512,)\n",
      "test set: (6513, 14) (6513,)\n",
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "7732    43   Private  350661    Prof-school             15   \n",
      "6790    67   Private  217028        Masters             14   \n",
      "7891    24   Private   39827   Some-college             10   \n",
      "25889   34   Private  211948        HS-grad              9   \n",
      "19135   19   Private  136306           11th              7   \n",
      "\n",
      "            marital-status          occupation    relationship    race  \\\n",
      "7732             Separated        Tech-support   Not-in-family   White   \n",
      "6790         Never-married       Other-service   Not-in-family   White   \n",
      "7891    Married-civ-spouse   Machine-op-inspct            Wife   Other   \n",
      "25889             Divorced               Sales   Not-in-family   White   \n",
      "19135        Never-married     Farming-fishing       Own-child   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
      "7732      Male             0             0              50        Columbia  \n",
      "6790    Female             0             0              40   United-States  \n",
      "7891    Female             0             0              40     Puerto-Rico  \n",
      "25889   Female             0          1590              40   United-States  \n",
      "19135     Male             0             0              24   United-States  \n",
      "       age          workclass  fnlwgt      education  education-num  \\\n",
      "13614   22            Private  406978      Bachelors             13   \n",
      "11356   34            Private   96480   Some-college             10   \n",
      "10726   49   Self-emp-not-inc  126268      Bachelors             13   \n",
      "30801   34          State-gov  173266        HS-grad              9   \n",
      "24444   28            Private  200733        HS-grad              9   \n",
      "\n",
      "            marital-status        occupation     relationship    race  \\\n",
      "13614        Never-married   Exec-managerial   Other-relative   White   \n",
      "11356            Separated   Exec-managerial        Unmarried   White   \n",
      "10726   Married-civ-spouse      Craft-repair          Husband   White   \n",
      "30801   Married-civ-spouse      Tech-support          Husband   White   \n",
      "24444   Married-civ-spouse      Craft-repair          Husband   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
      "13614   Female             0             0              40   United-States  \n",
      "11356   Female             0             0              40   United-States  \n",
      "10726     Male             0             0              50   United-States  \n",
      "30801     Male             0             0              40   United-States  \n",
      "24444     Male             0             0              40   United-States  \n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=random_state)\n",
    "print('training set:',X_train.shape, y_train.shape) # 60% of points are in train\n",
    "print(X_other.shape, y_other.shape) # 40% of points are in other\n",
    "print(X_train.head())\n",
    "\n",
    "# second split to separate out the validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=random_state)\n",
    "print('validation set:',X_val.shape, y_val.shape) # 20% of points are in validation\n",
    "print('test set:',X_test.shape, y_test.shape) # 20% of points are in test\n",
    "print(X_val.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomness due to splitting\n",
    "- the model performance, validation and test scores will change depending on which points are in train, val, test\n",
    "    - inherent randomness or uncertainty of the ML pipeline\n",
    "- change the random state a couple of times and repeat the whole ML pipeline to assess how much the random splitting affects your test score\n",
    "    - you would expect a similar uncertainty when the model is deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting strategies for iid data: k-fold splitting\n",
    "\n",
    "<center><img src=\"figures/grid_search_cross_validation.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KFold in module sklearn.model_selection._split:\n",
      "\n",
      "class KFold(_BaseKFold)\n",
      " |  KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      " |  \n",
      " |  K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets. Split\n",
      " |  dataset into k consecutive folds (without shuffling by default).\n",
      " |  \n",
      " |  Each fold is then used once as a validation while the k - 1 remaining\n",
      " |  folds form the training set.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |  \n",
      " |  shuffle : bool, default=False\n",
      " |      Whether to shuffle the data before splitting into batches.\n",
      " |      Note that the samples within each split will not be shuffled.\n",
      " |  \n",
      " |  random_state : int or RandomState instance, default=None\n",
      " |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      " |      indices, which controls the randomness of each fold. Otherwise, this\n",
      " |      parameter has no effect.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import KFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([1, 2, 3, 4])\n",
      " |  >>> kf = KFold(n_splits=2)\n",
      " |  >>> kf.get_n_splits(X)\n",
      " |  2\n",
      " |  >>> print(kf)\n",
      " |  KFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in kf.split(X):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [2 3] TEST: [0 1]\n",
      " |  TRAIN: [0 1] TEST: [2 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The first ``n_samples % n_splits`` folds have size\n",
      " |  ``n_samples // n_splits + 1``, other folds have size\n",
      " |  ``n_samples // n_splits``, where ``n_samples`` is the number of samples.\n",
      " |  \n",
      " |  Randomized CV splitters may return different results for each call of\n",
      " |  split. You can make the results identical by setting `random_state`\n",
      " |  to an integer.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  StratifiedKFold\n",
      " |      Takes group information into account to avoid building folds with\n",
      " |      imbalanced class distributions (for binary or multiclass\n",
      " |      classification tasks).\n",
      " |  \n",
      " |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      " |  \n",
      " |  RepeatedKFold: Repeats K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,), default=None\n",
      " |          The target variable for supervised learning problems.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "help(KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14) (26048,)\n",
      "test set: (6513, 14) (6513,)\n",
      "   training set: (20838, 14) (20838,)\n",
      "   validation set: (5210, 14) (5210,)\n",
      "       age   workclass      education\n",
      "27240   38     Private      Bachelors\n",
      "4       28     Private      Bachelors\n",
      "14242   34     Private        HS-grad\n",
      "16461   58     Private   Some-college\n",
      "2209    49   Local-gov        HS-grad\n",
      "   training set: (20838, 14) (20838,)\n",
      "   validation set: (5210, 14) (5210,)\n",
      "       age   workclass   education\n",
      "5514    33   Local-gov   Bachelors\n",
      "32240   21     Private   Assoc-voc\n",
      "8615    33     Private        10th\n",
      "7743    20     Private     HS-grad\n",
      "20097   39     Private   Assoc-voc\n",
      "   training set: (20838, 14) (20838,)\n",
      "   validation set: (5210, 14) (5210,)\n",
      "       age          workclass      education\n",
      "9876    27            Private   Some-college\n",
      "5455    44            Private      Bachelors\n",
      "29805   62   Self-emp-not-inc      Bachelors\n",
      "15081   20            Private        HS-grad\n",
      "13770   40            Private     Assoc-acdm\n",
      "   training set: (20839, 14) (20839,)\n",
      "   validation set: (5209, 14) (5209,)\n",
      "       age          workclass      education\n",
      "19777   36            Private      Assoc-voc\n",
      "10781   58   Self-emp-not-inc            9th\n",
      "9747    24            Private      Bachelors\n",
      "327     43            Private   Some-college\n",
      "24431   25            Private        HS-grad\n",
      "   training set: (20839, 14) (20839,)\n",
      "   validation set: (5209, 14) (5209,)\n",
      "       age workclass     education\n",
      "17203   33   Private       HS-grad\n",
      "12114   36   Private   Prof-school\n",
      "231     41   Private       HS-grad\n",
      "3272    30   Private          10th\n",
      "26009   19   Private          11th\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "# first split to separate out the test set\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "print(X_other.shape,y_other.shape)\n",
    "print('test set:',X_test.shape,y_test.shape)\n",
    "\n",
    "# do KFold split on other\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print('   training set:',X_train.shape, y_train.shape) \n",
    "    print('   validation set:',X_val.shape, y_val.shape) \n",
    "    # the validation set contains different points in each iteration\n",
    "    print(X_val[['age','workclass','education']].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How many splits should I create?\n",
    "- tough question, 3-5 is most common\n",
    "- if you do $n$ splits, $n$ models will be trained, so the larger the $n$, the most computationally intensive it will be to train the models\n",
    "- KFold is usually better suited for small datasets\n",
    "- KFold is good to estimate uncertainty due to random splitting of train and val, but it is not perfect\n",
    "    - the test set remains the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why shuffling iid data is important?\n",
    "- by default, data is not shuffled by Kfold which can introduce errors!\n",
    "<center><img src=\"figures/kfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced data\n",
    "- imbalanced data: only a small fraction of the points are in one of the classes, usually ~5% or less but there is no hard limit here\n",
    "- examples:\n",
    "    - people visit a bank's website. do they sign up for a new credit card?\n",
    "        - most customers just browse and leave the page\n",
    "        - usually 1% or less of the customers get a credit card (class 1), the rest leaves the page without signing up (class 0).\n",
    "    - fraud detection\n",
    "        - only a tiny fraction of credit card payments are fraudulent\n",
    "    - rare disease diagnosis\n",
    "- the issue with imbalanced data:\n",
    "    - if you apply train_test_split or KFold, you might not have class 1 points in one of your sets by chance\n",
    "    - this is what we need to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: stratified splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**balance without stratification:**\n",
      " <=50K    0.758855\n",
      " >50K     0.241145\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K    0.75476\n",
      " >50K     0.24524\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K    0.764625\n",
      " >50K     0.235375\n",
      "Name: gross-income, dtype: float64\n",
      "**balance with stratification:**\n",
      " <=50K    0.759214\n",
      " >50K     0.240786\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K    0.759214\n",
      " >50K     0.240786\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K    0.759097\n",
      " >50K     0.240903\n",
      "Name: gross-income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=random_state)\n",
    "\n",
    "print('**balance without stratification:**')\n",
    "# a variation on the order of 1% which would be too much for imbalanced data!\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=random_state)\n",
    "print('**balance with stratification:**')\n",
    "# very little variation (in the 4th decimal point only) which is important if the problem is imbalanced\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stratified folds\n",
    "<center><img src=\"figures/stratified_kfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StratifiedKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class StratifiedKFold(_BaseKFold)\n",
      " |  StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      " |  \n",
      " |  Stratified K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets.\n",
      " |  \n",
      " |  This cross-validation object is a variation of KFold that returns\n",
      " |  stratified folds. The folds are made by preserving the percentage of\n",
      " |  samples for each class.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |  \n",
      " |  shuffle : bool, default=False\n",
      " |      Whether to shuffle each class's samples before splitting into batches.\n",
      " |      Note that the samples within each split will not be shuffled.\n",
      " |  \n",
      " |  random_state : int or RandomState instance, default=None\n",
      " |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      " |      indices, which controls the randomness of each fold for each class.\n",
      " |      Otherwise, leave `random_state` as `None`.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import StratifiedKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([0, 0, 1, 1])\n",
      " |  >>> skf = StratifiedKFold(n_splits=2)\n",
      " |  >>> skf.get_n_splits(X, y)\n",
      " |  2\n",
      " |  >>> print(skf)\n",
      " |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in skf.split(X, y):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [1 3] TEST: [0 2]\n",
      " |  TRAIN: [0 2] TEST: [1 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The implementation is designed to:\n",
      " |  \n",
      " |  * Generate test sets such that all contain the same distribution of\n",
      " |    classes, or as close as possible.\n",
      " |  * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
      " |    ``y = [1, 0]`` should not change the indices generated.\n",
      " |  * Preserve order dependencies in the dataset ordering, when\n",
      " |    ``shuffle=False``: all samples from class k in some test set were\n",
      " |    contiguous in y, or separated in y by samples from classes other than k.\n",
      " |  * Generate test sets where the smallest and largest differ by at most one\n",
      " |    sample.\n",
      " |  \n",
      " |  .. versionchanged:: 0.22\n",
      " |      The previous implementation did not follow the last constraint.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StratifiedKFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  split(self, X, y, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |          Note that providing ``y`` is sufficient to generate the splits and\n",
      " |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      " |          ``X`` instead of actual training data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |          Stratification is done based on the y labels.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting `random_state`\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "help(StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test balance:  <=50K    0.75879\n",
      " >50K     0.24121\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.756982\n",
      " >50K     0.243018\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.768522\n",
      " >50K     0.231478\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.757702\n",
      " >50K     0.242298\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.765643\n",
      " >50K     0.234357\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.761014\n",
      " >50K     0.238986\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.752399\n",
      " >50K     0.247601\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.758866\n",
      " >50K     0.241134\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.760991\n",
      " >50K     0.239009\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.761889\n",
      " >50K     0.238111\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.748896\n",
      " >50K     0.251104\n",
      "Name: gross-income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# what we did before: variance in balance on the order of 1%\n",
    "random_state = 42\n",
    "\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "print('test balance:',y_test.value_counts(normalize=True))\n",
    "\n",
    "# do KFold split on other\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print('train balance:')\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print('val balance:')\n",
    "    print(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test balance:  <=50K    0.759251\n",
      " >50K     0.240749\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.75919\n",
      " >50K     0.24081\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.759117\n",
      " >50K     0.240883\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.75919\n",
      " >50K     0.24081\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.759117\n",
      " >50K     0.240883\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.75919\n",
      " >50K     0.24081\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.759117\n",
      " >50K     0.240883\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.759154\n",
      " >50K     0.240846\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.759263\n",
      " >50K     0.240737\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K    0.759154\n",
      " >50K     0.240846\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K    0.759263\n",
      " >50K     0.240737\n",
      "Name: gross-income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# stratified K Fold: variation in balance is very small (4th decimal point)\n",
    "random_state = 42\n",
    "\n",
    "# stratified train-test split\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,stratify=y,random_state=random_state)\n",
    "print('test balance:',y_test.value_counts(normalize=True))\n",
    "\n",
    "# do StratifiedKFold split on other\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print('train balance:')\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print('val balance:')\n",
    "    print(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Split non-IID data\n",
    "### Learning objectives of this module:\n",
    "- list examples of non-IID datasets\n",
    "- apply non-IID splitting techniques\n",
    "- identify when a custom splitting strategy is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of non-iid data\n",
    "- if there is any sort of time or group structure in your data, it is likely non-iid\n",
    "    - group structure:\n",
    "        - each point is someone's visit to the ER and some people visited the ER multiple times\n",
    "        - each point is stats of a youtube video and the stats are collected weekly, one of the stats is whether it is featured\n",
    "        - each point is a customer's visit to CVS and customers tend to return regularly\n",
    "    - time structure\n",
    "        - each point is the stocks price at a given time\n",
    "        - eahc point is a person's health or activity status\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-based split: GroupShuffleSplit\n",
    "<center><img src=\"figures/groupshufflesplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "X = np.ones(shape=(8, 2))\n",
    "y = np.ones(shape=(8, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=10, train_size=.8, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-based split: GroupKFold\n",
    "<center><img src=\"figures/groupkfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GroupKFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data leakage in time series data is similar!\n",
    "- do NOT use information in validation or test which will not be available once your model is deployed\n",
    "   - don't use future information!\n",
    "   \n",
    "<center><img src=\"figures/timeseriessplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Preprocess continuous and categorical features\n",
    "### Learning objectives of this module:\n",
    "- describe the two motivating concepts behind preprocessing\n",
    "- apply various preprocessors to categorical and continuous features\n",
    "- perform preprocessing with a sklearn pipeline and ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data almost never comes in a format that's directly usable in ML\n",
    "- ML works with numerical data but some columns can be text (e.g., home country, educational level, gender, race)\n",
    "    - some ML algorithms accept (and prefer) a non-numerical feature matrix (like [CatBoost](https://catboost.ai/) ) but that's not standard\n",
    "    - sklearn throws an error message if the feature matrix contains non-numerical elements\n",
    "- the order of magnitude of numerical features can vary greatly which is not good for most ML algorithms (e.g., salary in USD, age in years, time spent on the site in sec)\n",
    "    - many ML algorithms are distance-based and they perform better and converge faster if the features are standardized (features have a mean of 0 and the same standard deviation, usually 1)\n",
    "        - Lasso and Ridge regression because of the penalty term, K Nearest Neightbors, SVM, linear models if you want to use the coefficients to measure feature importance (more on this in part 6), neural networks\n",
    "    - tree-based methods don't require standardization \n",
    "    - check out part 1 to learn more about linear and logistic regression, Lasso and Ridge\n",
    "    - check out part 4 to learn more about SVMs, tree-based methods, and K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### scikit-learn transformers to the rescue!\n",
    "\n",
    "Preprocessing is done with various transformers. All transformes have three methods:\n",
    "- **fit** method: estimates parameters necessary to do the transformation,\n",
    "- **transform** method: transforms the data based on the estimated parameters,\n",
    "- **fit_transform** method: both steps are performed at once, this can be faster than doing the steps separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transformers we cover \n",
    "- **OrdinalEncoder** - converts categorical features into an integer array\n",
    "- **OneHotEncoder** - converts categorical features into dummy arrays\n",
    "- **StandardScaler** - standardizes continuous features by removing the mean and scaling to unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ordered categorical data: OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have a categorical feature and training and test sets\n",
    "\n",
    "The cateogies can be ordered or ranked\n",
    "\n",
    "E.g., educational level in the adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_edu = {'educational level':['Bachelors','Masters','Bachelors','Doctorate','HS-grad','Masters']} \n",
    "test_edu = {'educational level':['HS-grad','Masters','Masters','College','Bachelors']}\n",
    "\n",
    "X_train = pd.DataFrame(train_edu)\n",
    "X_test = pd.DataFrame(test_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "help(OrdinalEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the encoder\n",
    "cats = ['HS-grad','Bachelors','Masters','Doctorate']\n",
    "\n",
    "enc = OrdinalEncoder(categories = [cats]) # The ordered list of \n",
    "# categories need to be provided. By default, the categories are alphabetically ordered!\n",
    "\n",
    "# fit the training data\n",
    "enc.fit(X_train)\n",
    "# print the categories - not really important because we manually gave the ordered list of categories\n",
    "print(enc.categories_)\n",
    "# transform X_train. We could have used enc.fit_transform(X_train) to combine fit and transform\n",
    "X_train_oe = enc.transform(X_train)\n",
    "print(X_train_oe)\n",
    "# transform X_test\n",
    "X_test_oe = enc.transform(X_test) # OrdinalEncoder always throws an error message if \n",
    "                                  # it encounters an unknown category in test\n",
    "print(X_test_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unordered categorical data: one-hot encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some categories cannot be ordered. e.g., workclass, relationship status\n",
    "\n",
    "first feature: gender (male, female, unknown)\n",
    "\n",
    "second feature: browser  used \n",
    "\n",
    "these categories cannot be ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'gender':['Male','Female','Unknown','Male','Female','Female'],\\\n",
    "         'browser':['Safari','Safari','Internet Explorer','Chrome','Chrome','Internet Explorer']}\n",
    "test = {'gender':['Female','Male','Unknown','Female'],'browser':['Chrome','Firefox','Internet Explorer','Safari']}\n",
    "\n",
    "X_train = pd.DataFrame(train)\n",
    "X_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# How do we convert this to numerical features?\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "help(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the encoder\n",
    "enc = OneHotEncoder(sparse=False) # by default, OneHotEncoder returns a sparse matrix. sparse=False returns a 2D array\n",
    "# fit the training data\n",
    "enc.fit(X_train)\n",
    "print('categories:',enc.categories_)\n",
    "print('feature names:',enc.get_feature_names())\n",
    "# transform X_train\n",
    "X_train_ohe = enc.transform(X_train)\n",
    "#print(X_train_ohe)\n",
    "# do all of this in one step\n",
    "X_train_ohe = enc.fit_transform(X_train)\n",
    "#print(X_train_ohe)\n",
    "\n",
    "# transform X_test\n",
    "X_test_ohe = enc.transform(X_test)\n",
    "print('X_test transformed')\n",
    "print(X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous features: StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'salary':[50_000,75_000,40_000,1_000_000,30_000,250_000,35_000,45_000]}\n",
    "test = {'salary':[25_000,55_000,1_500_000,60_000]}\n",
    "\n",
    "X_train = pd.DataFrame(train)\n",
    "X_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "help(StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "print(scaler.fit_transform(X_train))\n",
    "print(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How and when to do preprocessing in the ML pipeline?\n",
    "- **SPLIT YOUR DATA FIRST!**\n",
    "- **APPLY TRANSFORMER.FIT ONLY ON YOUR TRAINING DATA!** Then transform the validation and test sets.\n",
    "- One of the most common mistake practitioners make is leaking statistics!\n",
    "     - fit_transform is applied to the whole dataset, then the data is split into train/validation/test\n",
    "         - this is wrong because the test set statistics impacts how the training and validation sets are transformed\n",
    "         - but the test set must be separated from train and val, and val must be separated from train\n",
    "     - or fit_transform is applied to the train, then fit_transform is applied to the validation set, and fit_transform is applied to the test set\n",
    "         - this is wrong because the relative position of the points change\n",
    "<center><img src=\"figures/no_separate_scaling.png\" width=\"1200\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-learn's pipelines\n",
    "\n",
    "- Preprocessing and model training (not the splitting) can be chained together into a scikit-learn pipeline which consists of transformers and one final estimator which is usually your classifier or regression model.\n",
    "- It neatly combines the preprocessing steps and it helps to avoid leaking statistics.\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv('data/adult_data.csv')\n",
    "\n",
    "# let's separate the feature matrix X, and target variable y\n",
    "y = df['gross-income'] # remember, we want to predict who earns more than 50k or less than 50k\n",
    "X = df.loc[:, df.columns != 'gross-income'] # all other columns are features\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=random_state)\n",
    "\n",
    "# second split to separate out the validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect which encoder to use on each feature\n",
    "# needs to be done manually\n",
    "ordinal_ftrs = ['education'] \n",
    "ordinal_cats = [[' Preschool',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' 10th',' 11th',' 12th',' HS-grad',\\\n",
    "                ' Some-college',' Assoc-voc',' Assoc-acdm',' Bachelors',' Masters',' Prof-school',' Doctorate']]\n",
    "onehot_ftrs = ['workclass','marital-status','occupation','relationship','race','sex','native-country']\n",
    "std_ftrs = ['capital-gain','capital-loss','age','hours-per-week']\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "# for now we only preprocess, later on we will add other steps here\n",
    "# note the final scaler which is a standard scaler\n",
    "# the ordinal and one hot encoded features do not have a mean of 0 and an std of 1\n",
    "# the final scaler standardizes those features\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),('final scaler',StandardScaler())]) \n",
    "\n",
    "X_train_prep = clf.fit_transform(X_train)\n",
    "X_val_prep = clf.transform(X_val)\n",
    "X_test_prep = clf.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_prep.shape)\n",
    "\n",
    "print(np.mean(X_train_prep,axis=0))\n",
    "print(np.std(X_train_prep,axis=0))\n",
    "print(np.mean(X_val_prep,axis=0))\n",
    "print(np.std(X_val_prep,axis=0))\n",
    "print(np.mean(X_test_prep,axis=0))\n",
    "print(np.std(X_test_prep,axis=0))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
