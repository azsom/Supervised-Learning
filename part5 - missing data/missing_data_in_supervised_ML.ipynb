{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Missing data in supervised ML</center>\n",
    "### <center>Andras Zsom</center>\n",
    "<center>Lead Data Scientist and Adjunct Lecturer in Data Science</center>\n",
    "<center>Center for Computation and Visualization</center>\n",
    "<center>Brown University</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About me\n",
    "- Born and raised in Hungary\n",
    "- Astrophysics PhD at MPIA, Heidelberg, Germany\n",
    "- Postdoctoral researcher at MIT (still in astrophysics at the time)\n",
    "- Started at Brown in December 2015 as a Data Scientist\n",
    "- Promoted to Lead Data Scientist in 2017\n",
    "- Adjunct Lecturer in Data Science last fall and this fall\n",
    "   - Teaching the course *DATA1030: Hands-on data science*, a mandatory course in the Data Science master's program at Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science at Brown\n",
    "- Center for Computation and Visualization (CCV) - https://ccv.brown.edu/\n",
    "- Institutional Data group\n",
    "   - Data-driven decision support and predictive modeling for Brownâ€™s administrative units\n",
    "   - Academic research on data-intensive projects\n",
    "   - Data science consulting for industry partners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will be able to\n",
    "- Describe the three main types of missingness patterns\n",
    "- Evaluate simple approaches for handling missing values\n",
    "- Apply XGBoost to a dataset with missing values\n",
    "- Apply multivariate imputation\n",
    "- Apply the reduced-features model (also called the pattern submodel approach)\n",
    "- Decide which approach is best for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Before we start, a few words on our dataset: kaggle house price\n",
    "- good for educational purposes\n",
    "   - messy data that requires quite a bit of preprocessing\n",
    "   - a nice mixture of continuous, ordinal, and categorical features, each feature type has missing values\n",
    "- lots of excellent kernels on kaggle\n",
    "   - check them out [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n",
    "- dataset and description available in repo\n",
    "   - let's take a look!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing values often occur in datasets\n",
    "- survey data: not everyone answers all the questions\n",
    "- medical data: not all tests/treatments/etc are performed on all patients\n",
    "- sensor can be offline or malfunctioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing values are an issue for multiple reasons\n",
    "\n",
    "#### Concenptual reason\n",
    "- missing values can introduce biases\n",
    "    - bias: the samples (the data points) are not representative of the underlying distribution/population\n",
    "    - any conclusion drawn from a biased dataset is also biased.\n",
    "    - rich people tend to not fill out survey questions about their salaries and the mean salary estimated from survey data tend to be lower than true value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Practical reason\n",
    "- missing values (NaN, NA, inf) are incompatible with sklearn\n",
    "   - all values in an array need to be numerical otherwise sklearn will throw a *ValueError*\n",
    "- there are a few supervised ML techniques that work with missing values (e.g., XGBoost, CatBoost)\n",
    "   - we will cover those later today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- **Describe the three main types of missingness patterns**\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Missing data patterns\n",
    "\n",
    "- **MCAR** - Missing Complete At Random\n",
    "   - some people skip some survey questions by accident\n",
    "- **MAR** - Missing At Random\n",
    "   - males are less likely to fill out a survey on depression\n",
    "   - this has nothing to do with their level of depression after accounting for maleness\n",
    "- **MNAR** - Missing Not At Random\n",
    "   - depressed people are less likely to fill out a survey on depression due to their level of depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MCAR test\n",
    "\n",
    "- MCAR can be diagnosed with a statistical test ([Little, 1988](https://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478722))\n",
    "   - python implementation available in the [pymice](https://github.com/RianneSchouten/pymice) package or in the skipped slide\n",
    "- Caveat: it can differentiate between MCAR and MAR only, it misses MNAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# from the pymice package \n",
    "# https://github.com/RianneSchouten/pymice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def mcar_test(data):\n",
    "    \"\"\" Implementation of Little's MCAR test\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas DataFrame\n",
    "        An incomplete dataset with samples as index and variables as columns\n",
    "    Returns\n",
    "    -------\n",
    "    p_value: Float\n",
    "        This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "        'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "    \"\"\"\n",
    "\n",
    "    if not checks_input_mcar_tests(data):\n",
    "        raise Exception(\"Input not correct\")\n",
    "\n",
    "    dataset = data.copy()\n",
    "    vars = dataset.dtypes.index.values\n",
    "    n_var = dataset.shape[1]\n",
    "\n",
    "    # mean and covariance estimates\n",
    "    # ideally, this is done with a maximum likelihood estimator\n",
    "    gmean = dataset.mean()\n",
    "    gcov = dataset.cov()\n",
    "\n",
    "    # set up missing data patterns\n",
    "    r = 1 * dataset.isnull()\n",
    "    mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "    sorted_mdp = sorted(np.unique(mdp))\n",
    "    n_pat = len(sorted_mdp)\n",
    "    correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "    dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "    # calculate statistic and df\n",
    "    pj = 0\n",
    "    d2 = 0\n",
    "    for i in range(n_pat):\n",
    "        dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "        select_vars = ~dataset_temp.isnull().any()\n",
    "        pj += np.sum(select_vars)\n",
    "        select_vars = vars[select_vars]\n",
    "        means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "        select_cov = gcov.loc[select_vars, select_vars]\n",
    "        mj = len(dataset_temp)\n",
    "        parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "        d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "    df = pj - n_var\n",
    "\n",
    "    # perform test and save output\n",
    "    p_value = 1 - st.chi2.cdf(d2, df)\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MCAR, MAR, MNAR are nice in theory, pretty useless in practice\n",
    "- it can be challenging to infer the missingness pattern from an incomplete dataset\n",
    "   - There is a statistical test to differentiate MCAR and MAR\n",
    "   - MNAR is difficult/impossible to diagnose to the best of my knowledge\n",
    "- multiple patterns can be present in the data\n",
    "   - even worse, multiple patterns can be present in one feature!\n",
    "   - missing values in a feature can occur due to a mix of MCAR, MAR, MNAR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- **Evaluate simple approaches for handling missing values**\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple approaches for handling missing values\n",
    "- 1) categorical/ordinal features: treat missing values as another category\n",
    "    - missing values in categorical/ordinal features are not a big deal\n",
    "- 2) continuous features: this is the tough part\n",
    "    - sklearn's SimpleImputer\n",
    "- 3) exclude points or features with missing values\n",
    "    - might be OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1a) Missing values in a categorical feature\n",
    "- YAY - this is not an issue at all!\n",
    "- Categorical feature needs to be one-hot encoded anyway\n",
    "- Just replace the missing values with 'NA' or 'missing' and treat it as a separate category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1b) Missing values in a ordinal feature\n",
    "- this can be a bit trickier but usually fine\n",
    "- Ordinal encoder is applied to ordinal features\n",
    "    - where does 'NA' or 'missing' fit into the order of the categories?\n",
    "    - usually first or last\n",
    "- if you can figure this out, you are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's load the data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "# drop the ID\n",
    "df.drop(columns=['Id'],inplace=True)\n",
    "\n",
    "# the target variable\n",
    "y = df['SalePrice']\n",
    "df.drop(columns=['SalePrice'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = df.values\n",
    "print(X.shape)\n",
    "# the feature names\n",
    "ftrs = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 79)\n",
      "(292, 79)\n",
      "(292, 79)\n"
     ]
    }
   ],
   "source": [
    "# let's split to train, test, and holdout\n",
    "X_other, X_holdout, y_other, y_holdout = train_test_split(df, y, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_other, y_other, test_size=0.25, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# collect the various features\n",
    "cat_ftrs = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2',\\\n",
    "            'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation',\\\n",
    "           'Heating','CentralAir','Electrical','GarageType','PavedDrive','MiscFeature','SaleType','SaleCondition']\n",
    "ordinal_ftrs = ['LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\\\n",
    "               'BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish',\\\n",
    "               'GarageQual','GarageCond','PoolQC','Fence']\n",
    "ordinal_cats = [['Reg','IR1','IR2','IR3'],['AllPub','NoSewr','NoSeWa','ELO'],['Gtl','Mod','Sev'],\\\n",
    "               ['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Po','Fa','TA','Gd','Ex'],['NA','No','Mn','Av','Gd'],['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\\\n",
    "               ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Unf','RFn','Fin'],['NA','Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\n",
    "               ['NA','Fa','TA','Gd','Ex'],['NA','MnWw','GdWo','MnPrv','GdPrv']]\n",
    "num_ftrs = ['MSSubClass','LotFrontage','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd',\\\n",
    "             'MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\\\n",
    "             'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n",
    "             'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','WoodDeckSF',\\\n",
    "             'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotShape</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IR1</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IR1</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IR1</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Rec</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Min1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Rec</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotShape Utilities LandSlope ExterQual ExterCond BsmtQual BsmtCond  \\\n",
       "0         Reg    AllPub       Gtl        Gd        TA       Gd       TA   \n",
       "1         Reg    AllPub       Gtl        TA        TA       Gd       TA   \n",
       "2         IR1    AllPub       Gtl        Gd        TA       Gd       TA   \n",
       "3         IR1    AllPub       Gtl        TA        TA       TA       Gd   \n",
       "4         IR1    AllPub       Gtl        Gd        TA       Gd       TA   \n",
       "...       ...       ...       ...       ...       ...      ...      ...   \n",
       "1455      Reg    AllPub       Gtl        TA        TA       Gd       TA   \n",
       "1456      Reg    AllPub       Gtl        TA        TA       Gd       TA   \n",
       "1457      Reg    AllPub       Gtl        Ex        Gd       TA       Gd   \n",
       "1458      Reg    AllPub       Gtl        TA        TA       TA       TA   \n",
       "1459      Reg    AllPub       Gtl        Gd        TA       TA       TA   \n",
       "\n",
       "     BsmtExposure BsmtFinType1 BsmtFinType2 HeatingQC KitchenQual Functional  \\\n",
       "0              No          GLQ          Unf        Ex          Gd        Typ   \n",
       "1              Gd          ALQ          Unf        Ex          TA        Typ   \n",
       "2              Mn          GLQ          Unf        Ex          Gd        Typ   \n",
       "3              No          ALQ          Unf        Gd          Gd        Typ   \n",
       "4              Av          GLQ          Unf        Ex          Gd        Typ   \n",
       "...           ...          ...          ...       ...         ...        ...   \n",
       "1455           No          Unf          Unf        Ex          TA        Typ   \n",
       "1456           No          ALQ          Rec        TA          TA       Min1   \n",
       "1457           No          GLQ          Unf        Ex          Gd        Typ   \n",
       "1458           Mn          GLQ          Rec        Gd          Gd        Typ   \n",
       "1459           No          BLQ          LwQ        Gd          TA        Typ   \n",
       "\n",
       "     FireplaceQu GarageFinish GarageQual GarageCond PoolQC  Fence  \n",
       "0            NaN          RFn         TA         TA    NaN    NaN  \n",
       "1             TA          RFn         TA         TA    NaN    NaN  \n",
       "2             TA          RFn         TA         TA    NaN    NaN  \n",
       "3             Gd          Unf         TA         TA    NaN    NaN  \n",
       "4             TA          RFn         TA         TA    NaN    NaN  \n",
       "...          ...          ...        ...        ...    ...    ...  \n",
       "1455          TA          RFn         TA         TA    NaN    NaN  \n",
       "1456          TA          Unf         TA         TA    NaN  MnPrv  \n",
       "1457          Gd          RFn         TA         TA    NaN  GdPrv  \n",
       "1458         NaN          Unf         TA         TA    NaN    NaN  \n",
       "1459         NaN          Fin         TA         TA    NaN    NaN  \n",
       "\n",
       "[1460 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ordinal_ftrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "# ordinal encoder\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='constant',fill_value='NA')),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 221)\n",
      "(292, 221)\n",
      "(292, 221)\n"
     ]
    }
   ],
   "source": [
    "# fit_transform the training set\n",
    "X_prep = preprocessor.fit_transform(X_train)\n",
    "# little hacky, but collect feature names\n",
    "feature_names = preprocessor.transformers_[0][-1] + \\\n",
    "                list(preprocessor.named_transformers_['cat'][1].get_feature_names(cat_ftrs)) + \\\n",
    "                preprocessor.transformers_[2][-1]\n",
    "\n",
    "df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "print(df_train.shape)\n",
    "\n",
    "# transform the test\n",
    "df_test = preprocessor.transform(X_test)\n",
    "df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "print(df_test.shape)\n",
    "\n",
    "# transform  the holdout\n",
    "df_holdout = preprocessor.transform(X_holdout)\n",
    "df_holdout = pd.DataFrame(data=df_holdout,columns = feature_names)\n",
    "print(df_holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotShape</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotShape  Utilities  LandSlope  ExterQual  ExterCond  BsmtQual  BsmtCond  \\\n",
       "0         0.0        0.0        0.0        2.0        2.0       4.0       3.0   \n",
       "1         0.0        0.0        0.0        3.0        2.0       4.0       3.0   \n",
       "2         1.0        0.0        0.0        2.0        2.0       4.0       3.0   \n",
       "3         0.0        0.0        0.0        2.0        2.0       3.0       3.0   \n",
       "4         0.0        0.0        0.0        3.0        2.0       4.0       3.0   \n",
       "..        ...        ...        ...        ...        ...       ...       ...   \n",
       "871       0.0        0.0        0.0        2.0        2.0       3.0       3.0   \n",
       "872       0.0        0.0        0.0        3.0        2.0       4.0       3.0   \n",
       "873       0.0        0.0        0.0        2.0        3.0       3.0       3.0   \n",
       "874       0.0        0.0        0.0        3.0        2.0       4.0       3.0   \n",
       "875       1.0        0.0        0.0        3.0        2.0       4.0       3.0   \n",
       "\n",
       "     BsmtExposure  BsmtFinType1  BsmtFinType2  HeatingQC  KitchenQual  \\\n",
       "0             1.0           1.0           1.0        4.0          2.0   \n",
       "1             3.0           6.0           1.0        4.0          3.0   \n",
       "2             3.0           5.0           2.0        3.0          3.0   \n",
       "3             1.0           4.0           1.0        2.0          2.0   \n",
       "4             1.0           6.0           1.0        4.0          3.0   \n",
       "..            ...           ...           ...        ...          ...   \n",
       "871           1.0           3.0           1.0        2.0          2.0   \n",
       "872           1.0           1.0           1.0        4.0          3.0   \n",
       "873           1.0           1.0           1.0        2.0          2.0   \n",
       "874           2.0           1.0           1.0        3.0          4.0   \n",
       "875           1.0           1.0           1.0        4.0          3.0   \n",
       "\n",
       "     Functional  FireplaceQu  GarageFinish  GarageQual  GarageCond  PoolQC  \\\n",
       "0           7.0          0.0           2.0         3.0         3.0     0.0   \n",
       "1           7.0          4.0           2.0         3.0         3.0     0.0   \n",
       "2           7.0          0.0           2.0         3.0         4.0     0.0   \n",
       "3           7.0          2.0           2.0         3.0         3.0     0.0   \n",
       "4           7.0          0.0           2.0         3.0         3.0     0.0   \n",
       "..          ...          ...           ...         ...         ...     ...   \n",
       "871         7.0          0.0           1.0         3.0         3.0     0.0   \n",
       "872         7.0          0.0           2.0         3.0         3.0     0.0   \n",
       "873         5.0          0.0           2.0         3.0         3.0     0.0   \n",
       "874         7.0          4.0           2.0         3.0         3.0     0.0   \n",
       "875         7.0          4.0           2.0         3.0         3.0     0.0   \n",
       "\n",
       "     Fence  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      3.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "871    3.0  \n",
       "872    0.0  \n",
       "873    0.0  \n",
       "874    0.0  \n",
       "875    0.0  \n",
       "\n",
       "[876 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[ordinal_ftrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2) Continuous features: mean or median imputation\n",
    "- Imputation means you infer the missing values from the known part of the data\n",
    "- sklearn's SimpleImputer can do mean and median imputation\n",
    "- USUALLY A BAD IDEA!\n",
    "   - MCAR: mean/median of non-missing values is the same as the mean/median of the true underlying distribution, but the variances are different\n",
    "   - not MCAR: the mean/median and the variance of the completed dataset will be off\n",
    "   - supervised ML model is too confident (MCAR) or systematically off (not MCAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3) Exclude points or features with missing values\n",
    "\n",
    "- easy to do with pandas\n",
    "- it is an ACCEPTABLE approach under two conditions:\n",
    "    - Little's test supports MCAR (p > 0.05)\n",
    "    - only small fraction of points contain missing values (maybe a few percent?) OR the missing values are limited to one or a few features that can be dropped\n",
    "- if the MCAR assumption is justified, dropping points will not introduce biases to your model\n",
    "- due to the smaller sample size, the confidence of your model might suffer. \n",
    "- what will you do with missing values when you deploy the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions: (876, 221)\n",
      "the p value of the mcar test: 1.0\n",
      "fraction of missing values in features:\n",
      "LotFrontage    0.173516\n",
      "MasVnrArea     0.004566\n",
      "GarageYrBlt    0.050228\n",
      "dtype: float64\n",
      "fraction of points with missing values: 0.2237442922374429\n"
     ]
    }
   ],
   "source": [
    "print('data dimensions:',df_train.shape)\n",
    "print('the p value of the mcar test:',mcar_test(df_train))\n",
    "perc_missing_per_ftr = df_train.isnull().sum(axis=0)/df_train.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "frac_missing = sum(df_train.isnull().sum(axis=1)!=0)/df_train.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 221)\n",
      "(680, 221)\n",
      "(876, 218)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "# by default, rows/points are dropped\n",
    "df_r = df_train.dropna()\n",
    "print(df_r.shape)\n",
    "# drop features with missing values\n",
    "df_c = df_train.dropna(axis=1)\n",
    "print(df_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- **Apply XGBoost to a dataset with missing values**\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBoost and missing values\n",
    "- sklearn raises an error if the feature matrix (X) contains nans. \n",
    "- XGBoost doesn't! \n",
    "- If a feature with missing values is split:\n",
    "    - XGBoost tries to put the points with missing values to the left and right\n",
    "    - calculates the impurity measure for both options\n",
    "    - puts the points with missing values to the side with the lower impurity\n",
    "- if missingness correlates with the target variable, XGBoost extracts this info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test RMSE: 23486.925781\n",
      "the holdout RMSE: 31748.96283078089\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "param_grid = {\"learning_rate\": [0.03],\n",
    "              \"n_estimators\": [2000],\n",
    "              \"seed\": [0],\n",
    "              #\"n_jobs\": [-1],\n",
    "              #\"reg_alpha\": [0e0,0.1,0.31622777,1.,3.16227766,10.],\n",
    "              #\"reg_lambda\": [0e0,0.1,0.31622777,1.,3.16227766,10.],\n",
    "              \"missing\": [np.nan], \n",
    "              #\"max_depth\": [1,2,3,4,5],\n",
    "              \"colsample_bytree\": [0.9],              \n",
    "              \"subsample\": [0.66]}\n",
    "\n",
    "XGB = xgboost.XGBRegressor()\n",
    "XGB.set_params(**ParameterGrid(param_grid)[0])\n",
    "XGB.fit(df_train,y_train,early_stopping_rounds=50,eval_set=[(df_test, y_test)], verbose=False)\n",
    "print('the test RMSE:',XGB.evals_result()['validation_0']['rmse'][-1])\n",
    "y_holdout_pred = XGB.predict(df_holdout)\n",
    "print('the holdout RMSE:',np.sqrt(mean_squared_error(y_holdout,y_holdout_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- **Apply multivariate imputation**\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multivariate Imputation\n",
    "\n",
    "- models each feature with missing values as a function of other features\n",
    "   - at each step, a feature with nans is designated as target variable y and the other features are treated as feature matrix X\n",
    "   - a regressor is trained on (X, y) for known y\n",
    "   - then, the regressor is used to predict the missing values of y\n",
    "- in the ML pipeline:\n",
    "   - create n imputed datasets\n",
    "   - run all of them through the ML pipeline\n",
    "   - generate n holdout scores\n",
    "   - the uncertainty in the holdout scores is due to the uncertainty in imputation\n",
    "- works on MCAR and MAR, fails on MNAR\n",
    "- paper [here](https://www.jstatsoft.org/article/view/v045i03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# sklearn's IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotFrontage  MasVnrArea  GarageYrBlt\n",
      "0     0.424926   -0.573303     0.979398\n",
      "1          NaN    0.492835     1.018748\n",
      "2          NaN   -0.573303     0.192399\n",
      "3    -0.049970    0.810076    -0.476551\n",
      "4    -1.474659   -0.022031     0.979398\n",
      "   LotFrontage  MasVnrArea  GarageYrBlt\n",
      "0     0.424926   -0.573303     0.979398\n",
      "1    -1.289018    0.492835     1.018748\n",
      "2    -0.287418   -0.573303     0.192399\n",
      "3    -0.049970    0.810076    -0.476551\n",
      "4    -1.474659   -0.022031     0.979398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/sklearn/impute/_iterative.py:670: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(df_train[['LotFrontage','MasVnrArea','GarageYrBlt']].head())\n",
    "\n",
    "imputer = IterativeImputer(estimator = RandomForestRegressor(n_estimators=10), random_state=0)\n",
    "X_impute = imputer.fit_transform(df_train)\n",
    "df_train_imp = pd.DataFrame(data=X_impute, columns = df_train.columns)\n",
    "\n",
    "print(df_train_imp[['LotFrontage','MasVnrArea','GarageYrBlt']].head())\n",
    "\n",
    "df_test_imp = pd.DataFrame(data=imputer.transform(df_test), columns = df_train.columns)\n",
    "df_holdout_imp = pd.DataFrame(data=imputer.transform(df_holdout), columns = df_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test RMSE: 23189.175781\n",
      "the holdout RMSE: 32290.240629124994\n"
     ]
    }
   ],
   "source": [
    "XGB.fit(df_train_imp,y_train,early_stopping_rounds=50,eval_set=[(df_test_imp, y_test)], verbose=False)\n",
    "print('the test RMSE:',XGB.evals_result()['validation_0']['rmse'][-1])\n",
    "y_holdout_pred = XGB.predict(df_holdout_imp)\n",
    "print('the holdout RMSE:',np.sqrt(mean_squared_error(y_holdout,y_holdout_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- **Apply the reduced-features model (also called the pattern submodel approach)**\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduced-features model (or pattern submodel approach)\n",
    "- first described in 2007 in a [JMLR article](http://www.jmlr.org/papers/v8/saar-tsechansky07a.html) as the reduced features model\n",
    "- in 2018, \"rediscovered\" as the pattern submodel approach in [Biostatistics](https://www.ncbi.nlm.nih.gov/pubmed/30203058)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>My holdout set:</center>\n",
    "\n",
    "| index \t| feature 1 \t| feature 2 \t| feature 3 \t| target var \t|\n",
    "|-------\t|:---------:\t|:---------:\t|:---------:\t|:----------:\t|\n",
    "| 0     \t|     <font color='red'>NA</font>    \t|     45    \t|     <font color='red'>NA</font>    \t|      0     \t|\n",
    "| 1     \t|     <font color='red'>NA</font>    \t|     <font color='red'>NA</font>    \t|     8     \t|      1     \t|\n",
    "| 2     \t|     12    \t|     6     \t|     34    \t|      0     \t|\n",
    "| 3     \t|     1     \t|     89    \t|     <font color='red'>NA</font>    \t|      0     \t|\n",
    "| 4     \t|     0     \t|     <font color='red'>NA</font>    \t|     47    \t|      1     \t|\n",
    "| 5     \t|    687    \t|     24    \t|     67    \t|      1     \t|\n",
    "| 6     \t|     <font color='red'>NA</font>    \t|     23    \t|     <font color='red'>NA</font>    \t|      1     \t|\n",
    "\n",
    "To predict points 0 and 6, I will use train and test points that are complete in feature 2.\n",
    "\n",
    "To predict point 1, I will use train and test points that are complete in feature 3.\n",
    "\n",
    "To predict point 2 and 5, I will use train and test points that are complete in features 1-3.\n",
    "\n",
    "Etc. We will train as many models as the number of patterns in holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to determine the patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "[False False False] 223\n",
      "[False False  True] 21\n",
      "[False  True False] 1\n",
      "[ True False False] 44\n",
      "[ True False  True] 2\n",
      "[ True  True False] 1\n"
     ]
    }
   ],
   "source": [
    "mask = df_holdout[['LotFrontage','MasVnrArea','GarageYrBlt']].isnull()\n",
    "unique_rows, counts = np.unique(mask, axis=0,return_counts=True)\n",
    "print(unique_rows.shape) # 6 patterns, we will train 6 models\n",
    "for i in range(len(counts)):\n",
    "    print(unique_rows[i],counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def xgb_model(X_train, Y_train, X_test, Y_test, X_holdout, Y_holdout, verbose=1):\n",
    "\n",
    "    # make into row vectors to avoid an obnoxious sklearn/xgb warning\n",
    "    Y_train = np.reshape(np.array(Y_train), (1, -1)).ravel()\n",
    "    Y_test = np.reshape(np.array(Y_test), (1, -1)).ravel()\n",
    "    Y_holdout = np.reshape(np.array(Y_holdout), (1, -1)).ravel()\n",
    "\n",
    "    XGB = xgboost.XGBRegressor(n_jobs=1)\n",
    "    \n",
    "    # find the best parameter set\n",
    "    param_grid = {\"learning_rate\": [0.03],\n",
    "                  \"n_estimators\": [2000],\n",
    "                  \"seed\": [0],\n",
    "                  #\"n_jobs\": [6],\n",
    "                  #\"reg_alpha\": [0e0,0.1,0.31622777,1.,3.16227766,10.],\n",
    "                  #\"reg_lambda\": [0e0,0.1,0.31622777,1.,3.16227766,10.],\n",
    "                  \"missing\": [np.nan], \n",
    "                  #\"max_depth\": [1,2,3,4,5],\n",
    "                  \"colsample_bytree\": [0.9],              \n",
    "                  \"subsample\": [0.66]}\n",
    "\n",
    "    pg = ParameterGrid(param_grid)\n",
    "\n",
    "    scores = np.zeros(len(pg))\n",
    "\n",
    "    for i in range(len(pg)):\n",
    "        if verbose >= 5:\n",
    "            print(\"Param set \" + str(i + 1) + \" / \" + str(len(pg)))\n",
    "        params = pg[i]\n",
    "        XGB.set_params(**params)\n",
    "        eval_set = [(X_test, Y_test)]\n",
    "        XGB.fit(X_train, Y_train,\n",
    "                early_stopping_rounds=50, eval_set=eval_set, verbose=False)# with early stopping\n",
    "        Y_test_pred = XGB.predict(X_test, ntree_limit=XGB.best_ntree_limit)\n",
    "        scores[i] = mean_squared_error(Y_test,Y_test_pred)\n",
    "\n",
    "    best_params = np.array(pg)[scores == np.max(scores)]\n",
    "    if verbose >= 4:\n",
    "        print('Test set max score and best parameters are:')\n",
    "        print(np.max(scores))\n",
    "        print(best_params)\n",
    "\n",
    "    # test the model on the holdout set with best parameter set\n",
    "    XGB.set_params(**best_params[0])\n",
    "    XGB.fit(X_train,Y_train,\n",
    "            early_stopping_rounds=50,eval_set=eval_set, verbose=False)\n",
    "    Y_holdout_pred = XGB.predict(X_holdout, ntree_limit=XGB.best_ntree_limit)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print ('The MSE is:',mean_squared_error(Y_holdout,Y_holdout_pred))\n",
    "    if verbose >= 2:\n",
    "        print ('The predictions are:')\n",
    "        print (Y_holdout_pred)\n",
    "    if verbose >= 3:\n",
    "        print(\"Feature importances:\")\n",
    "        print(XGB.feature_importances_)\n",
    "\n",
    "    return (mean_squared_error(Y_holdout,Y_holdout_pred), Y_holdout_pred, XGB.feature_importances_)\n",
    "\n",
    "# Function: Reduced-feature XGB model\n",
    "# all the inputs need to be pandas DataFrame\n",
    "def reduced_feature_xgb(X_train, Y_train, X_test, Y_test, X_holdout, Y_holdout):\n",
    "    \n",
    "    # find all unique patterns of missing value in holdout set\n",
    "    mask = X_holdout.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_Y_holdout_pred = pd.DataFrame()\n",
    "    \n",
    "    print('there are', len(unique_rows), 'unique missing value patterns.')\n",
    "    \n",
    "    # divide holdout sets into subgroups according to the unique patterns\n",
    "    for i in range(len(unique_rows)):\n",
    "        print ('working on unique pattern', i)\n",
    "        ## generate X_holdout subset that matches the unique pattern i\n",
    "        sub_X_holdout = pd.DataFrame()\n",
    "        sub_Y_holdout = pd.Series()\n",
    "        for j in range(len(mask)): # check each row in mask\n",
    "            row_mask = np.array(mask.iloc[j])\n",
    "            if np.array_equal(row_mask, unique_rows[i]): # if the pattern matches the ith unique pattern\n",
    "                sub_X_holdout = sub_X_holdout.append(X_holdout.iloc[j])# append the according X_holdout row j to the subset\n",
    "                sub_Y_holdout = sub_Y_holdout.append(Y_holdout.iloc[[j]])# append the according Y_holdout row j\n",
    "        sub_X_holdout = sub_X_holdout[X_holdout.columns[~unique_rows[i]]]\n",
    "        \n",
    "        ## choose the according reduced features for subgroups\n",
    "        sub_X_train = pd.DataFrame()\n",
    "        sub_Y_train = pd.DataFrame()\n",
    "        sub_X_test = pd.DataFrame()\n",
    "        sub_Y_test = pd.DataFrame()\n",
    "        # 1.cut the feature columns that have nans in the according sub_X_holdout\n",
    "        sub_X_train = X_train[X_train.columns[~unique_rows[i]]]\n",
    "        sub_X_test = X_test[X_test.columns[~unique_rows[i]]]\n",
    "        # 2.cut the rows in the sub_X_train and sub_X_test that have any nans\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_test = sub_X_test.dropna()   \n",
    "        # 3.cut the sub_Y_train and sub_Y_test accordingly\n",
    "        sub_Y_train = Y_train.iloc[sub_X_train.index]\n",
    "        sub_Y_test = Y_test.iloc[sub_X_test.index]\n",
    "        \n",
    "        # run XGB\n",
    "        sub_Y_holdout_pred = xgb_model(sub_X_train, sub_Y_train, sub_X_test, \n",
    "                                       sub_Y_test, sub_X_holdout, sub_Y_holdout, verbose=0)\n",
    "        sub_Y_holdout_pred = pd.DataFrame(sub_Y_holdout_pred[1],columns=['sub_Y_holdout_pred'],\n",
    "                                          index=sub_Y_holdout.index)\n",
    "        print('   RMSE:',np.sqrt(mean_squared_error(sub_Y_holdout,sub_Y_holdout_pred)))\n",
    "        # collect the holdout predictions\n",
    "        all_Y_holdout_pred = all_Y_holdout_pred.append(sub_Y_holdout_pred)\n",
    "        \n",
    "    # rank the final Y_holdout_pred according to original Y_holdout index\n",
    "    all_Y_holdout_pred = all_Y_holdout_pred.sort_index()\n",
    "    Y_holdout = Y_holdout.sort_index()\n",
    "               \n",
    "    # get global RMSE\n",
    "    total_RMSE = np.sqrt(mean_squared_error(Y_holdout,all_Y_holdout_pred))\n",
    "    \n",
    "    return total_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A python implementation is available on the skipped slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6 unique missing value patterns.\n",
      "working on unique pattern 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/ipykernel_launcher.py:76: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 35277.53669207676\n",
      "working on unique pattern 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/ipykernel_launcher.py:76: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 11607.857261825593\n",
      "working on unique pattern 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/ipykernel_launcher.py:76: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 1134.5625\n",
      "working on unique pattern 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/ipykernel_launcher.py:76: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 18366.394043603428\n",
      "working on unique pattern 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/ipykernel_launcher.py:76: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 18521.340554971906\n",
      "working on unique pattern 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/ipykernel_launcher.py:76: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RMSE: 65343.46875\n",
      "final RMSE: 32061.23877235819\n"
     ]
    }
   ],
   "source": [
    "print('final RMSE:',reduced_feature_xgb(df_train, y_train, df_test, y_test, df_holdout, y_holdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- **Decide which approach is best for your dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which approach is best for my data?\n",
    "- **XGB**: run $n$ XGB models with $n$ different seeds\n",
    "- **imputation**: prepare $n$ different imputations and run $n$ XGB models on them\n",
    "- **reduced-features**: run $n$ reduced-features model with $n$ different seeds\n",
    "- rank the three methods based on how significantly different the corresponding mean scores are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you can\n",
    "- Describe the three main types of missingness patterns\n",
    "- Evaluate simple approaches for handling missing values\n",
    "- Apply XGBoost to a dataset with missing values\n",
    "- Apply multivariate imputation\n",
    "- Apply the reduced-features model (also called the pattern submodel approach)\n",
    "- Decide which approach is best for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Thanks for your attention! </center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
